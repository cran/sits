% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sits_torch_spatial_encoder.R
\name{.torch_positional_encoder}
\alias{.torch_positional_encoder}
\alias{.torch_positional_encoding}
\title{Torch module for positional encoder}
\usage{
.torch_positional_encoding(timeline, dim_encoder = 128)
}
\arguments{
\item{timeline}{Timeline of input time series.}

\item{dim_encoder}{Dimension of the positional encoder.}
}
\value{
A tensor block.
}
\description{
Defines a torch module for positional encoding, based on
the concepts of Vaswani et al (2017) and Garnot et al ()

This function part of the implementation of the paper by Vivien Garnot
referenced below. We used the code made available by Maja Schneider in her
work with Marco Körner referenced below and available at
https://github.com/maja601/RC2020-psetae.
}
\references{
Vivien Sainte Fare Garnot and Loic Landrieu,
"Lightweight Temporal Self-Attention for Classifying Satellite Image
Time Series", https://arxiv.org/abs/2007.00586

Schneider, Maja; Körner, Marco,
"[Re] Satellite Image Time Series Classification
with Pixel-Set Encoders and Temporal Self-Attention." ReScience C7(2), 2021.

This function part of the implementation of the paper by Vivien Garnot
referenced below.

We used the code made available by Maja Schneider in her work with
Marco Körner referenced below and available at
https://github.com/maja601/RC2020-psetae.

Vivien Sainte Fare Garnot and Loic Landrieu,
"Lightweight Temporal Self-Attention for Classifying Satellite Image
Time Series", https://arxiv.org/abs/2007.00586

Schneider, Maja; Körner, Marco,
"[Re] Satellite Image Time Series Classification
with Pixel-Set Encoders and Temporal Self-Attention." ReScience C7(2), 2021.
}
\author{
Charlotte Pelletier, \email{charlotte.pelletier@univ-ubs.fr}

Gilberto Camara, \email{gilberto.camara@inpe.br}

Rolf Simoes, \email{rolf.simoes@inpe.br}

Felipe Souza, \email{lipecaso@gmail.com}
}
\keyword{internal}
