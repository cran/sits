% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sits_active_learning.R
\name{sits_confidence_sampling}
\alias{sits_confidence_sampling}
\alias{sits_confidence_samples}
\title{Suggest high confidence samples to increase the training set.}
\usage{
sits_confidence_samples(
  probs_cube,
  n = 20,
  min_margin = 0.9,
  min_dist_pixels = 10
)
}
\arguments{
\item{probs_cube}{A `sits` probability cube. See `sits_classify`.}

\item{n}{Number of suggested points per class.}

\item{min_margin}{Minimum margin of confidence to select a sample}

\item{min_dist_pixels}{Minimum distance among suggested points (in pixels).}
}
\value{
A data.frame with longitude & latitude in WGS84 of locations
            for each class that meet the criteria of minimum margin of
            confidence and minimum geographical distance between them.

if (sits_run_examples()) {
    # create a data cube
    data_dir <- system.file("extdata/raster/mod13q1", package = "sits")
    cube <- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir,
        delim = "_",
        parse_info = c("X1", "X2", "tile", "band", "date")
    )
    # build a random forest model
    samples_ndvi <- sits_select(samples_modis_4bands, bands = c("NDVI")
    rfor_model <- sits_train(samples_ndvi, ml_method = sits_rfor())
    # classify the cube
    probs_cube <- sits_classify(data = cube, ml_model = rfor_model)
    # run a Bayesian smoothing
    bayes_cube <- sits_smooth(probs_cube)
    # obtain a new set of samples for active learning
    # the samples are located in uncertain places
    new_samples <- sits_confidence_sampling(bayes_cube)
}
}
\description{
Suggest points for increasing the training set. These points are labelled
with high confidence so they can be added to the training set.
They need to have a satisfactory margin of confidence to be selected.
The input is a probability cube. For each label, the algorithm finds out
location where the machine learning model has high confidence in choosing
this label compared to all others. The algorithm also considers a
minimum distance between new labels, to minimize spatial autocorrelation
effects.

This function is best used in the following context
\itemize{
   \item{1. }{Select an initial set of samples.}
   \item{2. }{Train a machine learning model.}
   \item{3. }{Build a data cube and classify it using the model.}
   \item{4. }{Run a Bayesian smoothing in the resulting probability cube.}
   \item{5. }{Create an uncertainty cube.}
   \item{6. }{Perform confidence sampling.}
}
The Bayesian smoothing procedure will reduce the classification outliers
and thus increase the likelihood that the resulting pixels with provide
good quality samples for each class.
}
\author{
Alber Sanchez, \email{alber.sanchez@inpe.br}

Rolf Simoes, \email{rolf.simoes@inpe.br}

Felipe Carvalho, \email{felipe.carvalho@inpe.br}

Gilberto Camara, \email{gilberto.camara@inpe.br}
}
